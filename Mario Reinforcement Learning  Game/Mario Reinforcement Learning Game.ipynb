{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V53Q6SCaeEp-"
      },
      "source": [
        "# 1. Setup Mario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "g3gjMa92eEqB"
      },
      "outputs": [],
      "source": [
        "!pip install gym_super_mario_bros==7.3.0 nes_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7dcXqyheEqC"
      },
      "outputs": [],
      "source": [
        "# Import the game and joypad wrappers and simplified controls\n",
        "import gym_super_mario_bros\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvORzMMJeEqC"
      },
      "outputs": [],
      "source": [
        "# Setup game\n",
        "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "_GxYZlbseEqD"
      },
      "outputs": [],
      "source": [
        "\n",
        "done = True\n",
        "# Loop through each frame\n",
        "for step in range(100000):\n",
        "    if done:\n",
        "        # Start\n",
        "        env.reset()\n",
        "    state, reward, done, info = env.step(env.action_space.sample())\n",
        "    # Show the game on the screen\n",
        "    # env.render()\n",
        "# Close\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHFADxj-eEqD"
      },
      "source": [
        "# 2. Preprocess Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "DcQSCUTPeEqD"
      },
      "outputs": [],
      "source": [
        "# Install pytorch\n",
        "!pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "nrVPAKwxeEqE"
      },
      "outputs": [],
      "source": [
        "# Install stable baselines\n",
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcsDNg6IeEqE"
      },
      "outputs": [],
      "source": [
        "# Import Frame Stacker Wrapper and GrayScaling Wrapper\n",
        "from gym.wrappers import GrayScaleObservation\n",
        "# Import Vectorization Wrappers\n",
        "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
        "# Import Matplotlib\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkZRFlO3eEqE"
      },
      "outputs": [],
      "source": [
        "# 1. Create the base environment\n",
        "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "# 2. Simplify the controls\n",
        "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "# 3. Grayscale\n",
        "env = GrayScaleObservation(env, keep_dim=True)\n",
        "# 4. Wrap inside the Dummy Environment\n",
        "env = DummyVecEnv([lambda: env])\n",
        "# 5. Stack the frames\n",
        "env = VecFrameStack(env, 4, channels_order='last')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7FZxOd9eEqF"
      },
      "outputs": [],
      "source": [
        "state = env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMUVnSe8eEqF"
      },
      "outputs": [],
      "source": [
        "state, reward, done, info = env.step([5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "015noQRVeEqF"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,16))\n",
        "for idx in range(state.shape[3]):\n",
        "    plt.subplot(1,4,idx+1)\n",
        "    plt.imshow(state[0][:,:,idx])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW-0XkuAeEqG"
      },
      "source": [
        "# 3. Training the RL Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PY6yKE3beEqG"
      },
      "outputs": [],
      "source": [
        "# Import os for file path management\n",
        "import os\n",
        "# Import PPO for algos\n",
        "from stable_baselines3 import PPO\n",
        "# Import Base Callback for saving models\n",
        "from stable_baselines3.common.callbacks import BaseCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "gs94LPmdeEqG"
      },
      "outputs": [],
      "source": [
        "class TrainAndLoggingCallback(BaseCallback):\n",
        "\n",
        "    def __init__(self, check_freq, save_path, verbose=1):\n",
        "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "        self.save_path = save_path\n",
        "\n",
        "    def _init_callback(self):\n",
        "        if self.save_path is not None:\n",
        "            os.makedirs(self.save_path, exist_ok=True)\n",
        "\n",
        "    def _on_step(self):\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
        "            self.model.save(model_path)\n",
        "\n",
        "        return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAhzcRKzeEqG"
      },
      "outputs": [],
      "source": [
        "CHECKPOINT_DIR = './train/'\n",
        "LOG_DIR = './logs/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "bYA0_JUreEqH"
      },
      "outputs": [],
      "source": [
        "# Setup model saving callback\n",
        "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIc3NxVzeEqH"
      },
      "outputs": [],
      "source": [
        "# model architecture\n",
        "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001,\n",
        "            n_steps=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "AM9ATlUheEqH"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "model.learn(total_timesteps=1000000, callback=callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKsrYH02eEqH"
      },
      "outputs": [],
      "source": [
        "model.save('thisisatestmodel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THh9IVBjeEqH"
      },
      "source": [
        "# 4. Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooUOHEyJeEqH"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "model = PPO.load('./train/best_model_1000000')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Pv5sY1ReEqI"
      },
      "outputs": [],
      "source": [
        "state = env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UICLs1eJeEqI"
      },
      "outputs": [],
      "source": [
        "# Start the game\n",
        "state = env.reset()\n",
        "# Loop through the game\n",
        "while True:\n",
        "\n",
        "    action, _ = model.predict(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    env.render()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mario",
      "language": "python",
      "name": "mario"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}